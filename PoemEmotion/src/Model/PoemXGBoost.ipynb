{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fzFxSr_W8Hg",
        "outputId": "f06cce8b-1f0c-435e-d321-b7da51f7cfc5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Error loading corpus: Package 'corpus' not found in index\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('corpus')\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIiYZI2LXF1V"
      },
      "outputs": [],
      "source": [
        "# Load the stop words and lemmatizing model\n",
        "en_model = spacy.load('en_core_web_sm')\n",
        "stopwords = en_model.Defaults.stop_words\n",
        "wnl = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qo9ljz8QTpc6"
      },
      "outputs": [],
      "source": [
        "# create new token list lemmatized, rid of stop words and lower cased\n",
        "with open('token_list.txt') as f:\n",
        "  with open('processed_token_list.txt','w') as w:\n",
        "    for line in f:\n",
        "      tokens = [token.strip() for token in line.split(',')]\n",
        "      clean_tokens = [wnl.lemmatize(tokens[i]).lower() for i in range(len(tokens)-1) if wnl.lemmatize(tokens[i]) not in stopwords]\n",
        "      w.write(','.join(clean_tokens)+'\\n')\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roU0AzSveJNb"
      },
      "source": [
        "# Load Data from Processed Tokens List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QACwwmBzeNXk",
        "outputId": "b5095a37-0110-460d-c0e7-47cd60e3d743"
      },
      "outputs": [],
      "source": [
        "token_list_path = '/content/processed_token_list.txt'\n",
        "data = []\n",
        "with open(token_list_path) as f:\n",
        "  for line in f:\n",
        "    tokens = [token.strip() for token in line.split(',')]\n",
        "    data.append(\" \".join(tokens[:-1]))\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdnVBqXhMOgT",
        "outputId": "7a8d7e4c-c24d-432f-9bab-9910eca1e95d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "716"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7vszSroPY8j"
      },
      "outputs": [],
      "source": [
        "# Load Training Labels\n",
        "labels = []\n",
        "label_file = 'labels.txt'\n",
        "with open(label_file) as f:\n",
        "  for label in f:\n",
        "    labels.append(int(label.strip()))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfcPtMFJdckZ"
      },
      "source": [
        "# Process the data according to XGBoost's needs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWeu2fy0dZ-z",
        "outputId": "4c113faa-b5c5-4e75-b18c-6b3a349a332f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<716x7165 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 38482 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Vectorizing\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(binary = True)\n",
        "cv.fit(data)\n",
        "data_vectorized = cv.transform(data)\n",
        "data_vectorized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMZcOBZbamOF"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE()\n",
        "data_resampled, label_resampled = smote.fit_resample(data_vectorized, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUXbNCH2P6y7"
      },
      "outputs": [],
      "source": [
        "# split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_resampled, label_resampled, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1X8KGffRT7Q"
      },
      "outputs": [],
      "source": [
        "# creating a variable for the new train and test sets\n",
        "import xgboost as xgb\n",
        "xgb_train = xgb.DMatrix(X_train, y_train)\n",
        "xgb_test = xgb.DMatrix(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1ZvnW8lReq7"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA9gBka0RgRK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "num_classes = len(np.unique(labels))\n",
        "param = {'eta': 0.65,\n",
        "         'max_depth': 70,\n",
        "         'objective': 'multi:softmax',\n",
        "         'num_class': num_classes}\n",
        "\n",
        "xgb_model = xgb.train(param, xgb_train, num_boost_round = 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neKo3HCNSXq7",
        "outputId": "913c505d-3334-4ace-d2fb-70dd838dbeba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "145\n",
            "[5. 2. 0. 8. 7. 4. 4. 2. 4. 6.]\n"
          ]
        }
      ],
      "source": [
        "y_pred = xgb_model.predict(xgb_test)\n",
        "print(len(y_pred))\n",
        "print(y_pred[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOfjO9sAXdHZ",
        "outputId": "2662c67f-c136-43e3-8992-08b7f7b9a60a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Performance\n",
            "Test accuracy: 0.6896551724137931\n",
            "F1 score:      0.6915160100961318\n",
            "precision 0.7183750428070915\n",
            "recall 0.6896551724137931\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
        "print(\"XGBoost Performance\")\n",
        "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"F1 score:     \",f1_score(y_test, y_pred, average='weighted'))\n",
        "print(\"precision\", precision_score(y_test, y_pred, average='weighted'))\n",
        "print(\"recall\", recall_score(y_test, y_pred, average='weighted'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
